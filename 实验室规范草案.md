# 实验室规范草案

> 本规范旨在保障实验室资源高效、有序使用，促进成员协作与沟通。

---

## 一、联系方式

- **实验室同学联系方式**：[点击查看 Notion 通讯录](https://www.notion.so/your-page)  
  （请将上述链接替换为实际的 Notion 页面地址）

---

## 二、组会安排

- **时间**：每周六上午、下午
- **形式**：组会具体安排请关注群通知或联系负责人

---

## 三、服务器使用规范

### 3.1 账号管理

- **一人一号**：每位成员使用独立账号，禁止共用账号。
- **开号流程**：需使用服务器时，联系 **周拓**（或指定负责同学）申请开通账户。
- **责任归属**：独立账号便于定位资源占用责任人，便于协调与问题追溯。

### 3.2 资源使用原则

- **长时间占用**：需长时间占用 CPU/GPU 运行大计算量任务时，请提前告知服务器管理员，获得许可后再执行。
- **资源释放**：任务结束后及时释放资源，避免长期闲置占用。
- **禁止占满**：禁止在任何情况下占满 CPU 资源，至少留出 4 个核心保证基础服务运行。

### 3.3 闲置资源处理

- **长期占用且无活动**：若发现进程长期占用显存/内存且无实际计算活动（如 GPU 利用率长期为 0%），可先通过 `ps aux | grep [PID]` 查询所属用户，联系对应用户协调关停。
- **协调优先**：以沟通协调为主，提高资源利用率，而非监督同学。

### 3.4 GPU 状态监控（可选）

- 部署轻量级监控脚本，仅调用 NVIDIA 官方工具读取 GPU 状态（显存、利用率、占用用户/进程）。
- 脚本不占用 GPU，CPU 和内存消耗可忽略，不影响服务器正常使用。
- 将采集到的 GPU 状态（谁在用、用了多少、是否闲置）同步至服务器使用专用群，便于发现闲置进程并协调关停。

---

## 四、大模型 API 资源使用规范

### 4.1 部署原则

- **按需部署**：部署 VLLM 等推理服务前，请确认确有持续使用需求。
- **及时关停**：服务长期无请求时，请主动关停以释放显存，供他人使用。

### 4.2 资源占用说明

- VLLM 等推理服务启动后，模型常驻显存，即使无推理请求也会持续占用。
- 建议定期自查：`nvidia-smi` 查看显存占用，`ps aux | grep vllm` 查看自身服务状态。

### 4.3 协调机制

- 若发现显存被长期占用且利用率极低，可通过监控群或直接联系对应用户，友好沟通关停事宜。

---

## 五、其他规范

> （预留空间，可后续补充，例如：）
>
> - 实验室安全与值日
> - 设备使用与预约
> - 数据与文件管理
> - 财务与报销流程
> - 其他……

---

## 六、附则

- 本规范自公布之日起试行，可根据实际情况修订。
- 如有疑问，请联系实验室负责人或服务器管理员。
